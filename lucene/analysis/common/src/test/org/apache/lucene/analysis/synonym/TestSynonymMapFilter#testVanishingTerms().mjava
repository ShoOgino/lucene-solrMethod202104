  // LUCENE-3375
  public void testVanishingTerms() throws Exception {
    String testFile = "aaa => aaaa1 aaaa2 aaaa3\n" + "bbb => bbbb1 bbbb2\n";
    Analyzer synAnalyzer = new MockAnalyzer(random());
    SolrSynonymParser parser = new SolrSynonymParser(true, true, synAnalyzer);
    parser.parse(new StringReader(testFile));
    final SynonymMap map = parser.build();
    synAnalyzer.close();

    Analyzer analyzer =
        new Analyzer() {
          @Override
          protected TokenStreamComponents createComponents(String fieldName) {
            Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);
            return new TokenStreamComponents(tokenizer, new SynonymFilter(tokenizer, map, true));
          }
        };

    // where did my pot go?!
    assertAnalyzesTo(
        analyzer,
        "xyzzy bbb pot of gold",
        new String[] {"xyzzy", "bbbb1", "pot", "bbbb2", "of", "gold"});

    // this one nukes 'pot' and 'of'
    // xyzzy aaa pot of gold -> xyzzy aaaa1 aaaa2 aaaa3 gold
    assertAnalyzesTo(
        analyzer,
        "xyzzy aaa pot of gold",
        new String[] {"xyzzy", "aaaa1", "pot", "aaaa2", "of", "aaaa3", "gold"});
    analyzer.close();
  }

