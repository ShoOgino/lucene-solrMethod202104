  // test analyzer caching the tokenizer
  @Test
  public void testClose() throws IOException {
    Map<String, String> args =
        new HashMap<String, String>() {
          {
            put("sentenceModel", "en-test-sent.bin");
            put("tokenizerModel", "en-test-tokenizer.bin");
          }
        };
    OpenNLPTokenizerFactory factory = new OpenNLPTokenizerFactory(args);
    factory.inform(new ClasspathResourceLoader(getClass()));

    Tokenizer ts = factory.create(newAttributeFactory());
    ts.setReader(new StringReader(SENTENCES));

    ts.reset();
    ts.close();
    ts.reset();
    ts.setReader(new StringReader(SENTENCES));
    assertTokenStreamContents(ts, SENTENCES_punc);
    ts.close();
    ts.reset();
    ts.setReader(new StringReader(SENTENCES));
    assertTokenStreamContents(ts, SENTENCES_punc);
  }

