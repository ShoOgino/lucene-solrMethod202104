  @Test
  public void testAnalyze_custom() {
    AnalysisImpl analysis = new AnalysisImpl();
    Map<String, String> tkParams = new HashMap<>();
    tkParams.put("maxTokenLen", "128");
    CustomAnalyzerConfig.Builder builder =
        new CustomAnalyzerConfig.Builder("keyword", tkParams)
            .addTokenFilterConfig("lowercase", Collections.emptyMap());
    CustomAnalyzer analyzer = (CustomAnalyzer) analysis.buildCustomAnalyzer(builder.build());
    assertEquals("org.apache.lucene.analysis.custom.CustomAnalyzer", analyzer.getClass().getName());
    assertEquals(
        "org.apache.lucene.analysis.core.KeywordTokenizerFactory",
        analyzer.getTokenizerFactory().getClass().getName());
    assertEquals(
        "org.apache.lucene.analysis.core.LowerCaseFilterFactory",
        analyzer.getTokenFilterFactories().get(0).getClass().getName());

    String text = "Apache Lucene";
    List<Analysis.Token> tokens = analysis.analyze(text);
    assertNotNull(tokens);
  }

