  /**
   * Check that the positions of the terms in a document keep into account the fact that some of the
   * words were filtered by two StopwordFilters concatenated together.
   */
  public void testTokenPositionsWithConcatenatedStopwordFilters() throws IOException {
    // at least 1 token
    final int numberOfTokens = random().nextInt(MAX_NUMBER_OF_TOKENS - 1) + 1;
    StringBuilder sb = new StringBuilder();
    List<String> stopwords = new ArrayList<>(numberOfTokens);
    List<Integer> stopwordPositions = new ArrayList<>();
    generateTestSetWithStopwordsAndStopwordPositions(
        numberOfTokens, sb, stopwords, stopwordPositions);

    // we want to make sure that concatenating two list of stopwords
    // produce the same results of using one unique list of stopwords.
    // So we first generate a list of stopwords:
    // e.g.: [a, b, c, d, e]
    // and then we split the list in two disjoint partitions
    // e.g. [a, c, e] [b, d]
    int partition = random().nextInt(stopwords.size());
    Collections.shuffle(stopwords, random());
    final List<String> stopwordsRandomPartition = stopwords.subList(0, partition);
    final Set<String> stopwordsRemaining = new HashSet<>(stopwords);
    stopwordsRemaining.removeAll(
        stopwordsRandomPartition); // remove the first partition from all the stopwords

    CharArraySet firstStopSet = StopFilter.makeStopSet(stopwordsRandomPartition);
    logStopwords("Stopwords-first", stopwordsRandomPartition);
    CharArraySet secondStopSet = StopFilter.makeStopSet(new ArrayList<>(stopwordsRemaining), false);
    logStopwords("Stopwords-second", stopwordsRemaining);

    Reader reader = new StringReader(sb.toString());
    final MockTokenizer in1 = new MockTokenizer(MockTokenizer.WHITESPACE, false);
    in1.setReader(reader);

    // Here we create a stopFilter with the stopwords in the first partition and then we
    // concatenate it with the stopFilter created with the stopwords in the second partition
    StopFilter stopFilter = new StopFilter(in1, firstStopSet); // first part of the set
    StopFilter concatenatedStopFilter =
        new StopFilter(stopFilter, secondStopSet); // two stop filters concatenated!

    // ... and finally we check that the positions of the filtered tokens matched using the
    // concatenated
    // stopFilters match the positions of the filtered tokens using the unique original list of
    // stopwords
    doTestStopwordsPositions(concatenatedStopFilter, stopwordPositions, numberOfTokens);
  }

