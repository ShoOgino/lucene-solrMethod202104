    // Returns a ref
    LeafReader getParallelLeafReader(final LeafReader leaf, boolean doCache, long schemaGen) throws IOException {
      assert leaf instanceof SegmentReader;
      SegmentInfo info = ((SegmentReader) leaf).getSegmentInfo().info;

      long infoSchemaGen = getSchemaGen(info);

      if (DEBUG) System.out.println(Thread.currentThread().getName() + ": TEST: getParallelLeafReader: " + leaf + " infoSchemaGen=" + infoSchemaGen + " vs schemaGen=" + schemaGen + " doCache=" + doCache);

      if (infoSchemaGen == schemaGen) {
        if (DEBUG) System.out.println(Thread.currentThread().getName()+ ": TEST: segment is already current schemaGen=" + schemaGen + "; skipping");
        return null;
      }

      if (infoSchemaGen > schemaGen) {
        throw new IllegalStateException("segment infoSchemaGen (" + infoSchemaGen + ") cannot be greater than requested schemaGen (" + schemaGen + ")");
      }

      final SegmentIDAndGen segIDGen = new SegmentIDAndGen(StringHelper.idToString(info.getId()), schemaGen);

      // While loop because the parallel reader may be closed out from under us, so we must retry:
      while (true) {

        // TODO: make this sync finer, i.e. just the segment + schemaGen
        synchronized (this) {
          LeafReader parReader = parallelReaders.get(segIDGen);
      
          assert doCache || parReader == null;

          if (parReader == null) {

            Path leafIndex = segsPath.resolve(segIDGen.toString());

            final Directory dir = openDirectory(leafIndex);

            if (slowFileExists(dir, "done") == false) {
              if (DEBUG) System.out.println(Thread.currentThread().getName() + ": TEST: build segment index for " + leaf + " " + segIDGen + " (source: " + info.getDiagnostics().get("source") + ") dir=" + leafIndex);

              if (dir.listAll().length != 0) {
                // It crashed before finishing last time:
                if (DEBUG) System.out.println(Thread.currentThread().getName() + ": TEST: remove old incomplete index files: " + leafIndex);
                IOUtils.rm(leafIndex);
              }

              reindex(infoSchemaGen, schemaGen, leaf, dir);

              // Marker file, telling us this index is in fact done.  This way if we crash while doing the reindexing for a given segment, we will
              // later try again:
              dir.createOutput("done", IOContext.DEFAULT).close();
            } else {
              if (DEBUG) System.out.println(Thread.currentThread().getName() + ": TEST: segment index already exists for " + leaf + " " + segIDGen + " (source: " + info.getDiagnostics().get("source") + ") dir=" + leafIndex);
            }

            if (DEBUG) System.out.println(Thread.currentThread().getName() + ": TEST: now check index " + dir);
            //TestUtil.checkIndex(dir);

            SegmentInfos infos = SegmentInfos.readLatestCommit(dir);
            assert infos.size() == 1;
            final LeafReader parLeafReader = new SegmentReader(infos.info(0), Version.LATEST.major, IOContext.DEFAULT);

            //checkParallelReader(leaf, parLeafReader, schemaGen);

            if (DEBUG) System.out.println(Thread.currentThread().getName() + ": TEST: opened parallel reader: " + parLeafReader);
            if (doCache) {
              parallelReaders.put(segIDGen, parLeafReader);

              // Our id+gen could have been previously closed, e.g. if it was a merged segment that was warmed, so we must clear this else
              // the pruning may remove our directory:
              closedSegments.remove(segIDGen);

              parLeafReader.getReaderCacheHelper().addClosedListener(new ParallelReaderClosed(segIDGen, dir));

            } else {
              // Used only for merged segment warming:
              // Messy: we close this reader now, instead of leaving open for reuse:
              if (DEBUG) System.out.println("TEST: now decRef non cached refCount=" + parLeafReader.getRefCount());
              parLeafReader.decRef();
              dir.close();

              // Must do this after dir is closed, else another thread could "rm -rf" while we are closing (which makes MDW.close's
              // checkIndex angry):
              closedSegments.add(segIDGen);
              parReader = null;
            }
            parReader = parLeafReader;

          } else {
            if (parReader.tryIncRef() == false) {
              // We failed: this reader just got closed by another thread, e.g. refresh thread opening a new reader, so this reader is now
              // closed and we must try again.
              if (DEBUG) System.out.println(Thread.currentThread().getName()+ ": TEST: tryIncRef failed for " + parReader + "; retry");
              parReader = null;
              continue;
            }
            if (DEBUG) System.out.println(Thread.currentThread().getName()+ ": TEST: use existing already opened parReader=" + parReader + " refCount=" + parReader.getRefCount());
            //checkParallelReader(leaf, parReader, schemaGen);
          }

          // We return the new reference to caller
          return parReader;
        }
      }
    }

