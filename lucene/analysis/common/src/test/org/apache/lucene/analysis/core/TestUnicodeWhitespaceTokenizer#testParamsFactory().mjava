  public void testParamsFactory() throws IOException {

    // negative maxTokenLen
    IllegalArgumentException iae =
        expectThrows(
            IllegalArgumentException.class,
            () -> new WhitespaceTokenizerFactory(makeArgs("rule", "unicode", "maxTokenLen", "-1")));
    assertEquals(
        "maxTokenLen must be greater than 0 and less than 1048576 passed: -1", iae.getMessage());

    // zero maxTokenLen
    iae =
        expectThrows(
            IllegalArgumentException.class,
            () -> new WhitespaceTokenizerFactory(makeArgs("rule", "unicode", "maxTokenLen", "0")));
    assertEquals(
        "maxTokenLen must be greater than 0 and less than 1048576 passed: 0", iae.getMessage());

    // Added random param, should throw illegal error
    iae =
        expectThrows(
            IllegalArgumentException.class,
            () ->
                new WhitespaceTokenizerFactory(
                    makeArgs("rule", "unicode", "maxTokenLen", "255", "randomParam", "rValue")));
    assertEquals("Unknown parameters: {randomParam=rValue}", iae.getMessage());

    // tokeniser will split at 5, Token | izer, no matter what happens
    WhitespaceTokenizerFactory factory =
        new WhitespaceTokenizerFactory(makeArgs("rule", "unicode", "maxTokenLen", "5"));
    AttributeFactory attributeFactory = newAttributeFactory();
    Tokenizer tokenizer = factory.create(attributeFactory);
    StringReader reader = new StringReader("Tokenizer \ud801\udc1ctest");
    tokenizer.setReader(reader);
    assertTokenStreamContents(tokenizer, new String[] {"Token", "izer", "\ud801\udc1ctes", "t"});

    // tokeniser will split at 2, To | ke | ni | ze | r, no matter what happens
    factory = new WhitespaceTokenizerFactory(makeArgs("rule", "unicode", "maxTokenLen", "2"));
    attributeFactory = newAttributeFactory();
    tokenizer = factory.create(attributeFactory);
    reader = new StringReader("Tokenizer\u00A0test");
    tokenizer.setReader(reader);
    assertTokenStreamContents(tokenizer, new String[] {"To", "ke", "ni", "ze", "r", "te", "st"});

    // tokeniser will split at 10, no matter what happens,
    // but tokens' length are less than that
    factory = new WhitespaceTokenizerFactory(makeArgs("rule", "unicode", "maxTokenLen", "10"));
    attributeFactory = newAttributeFactory();
    tokenizer = factory.create(attributeFactory);
    reader = new StringReader("Tokenizer\u00A0test");
    tokenizer.setReader(reader);
    assertTokenStreamContents(tokenizer, new String[] {"Tokenizer", "test"});
  }

