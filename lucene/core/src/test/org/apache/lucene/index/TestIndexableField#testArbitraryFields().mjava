  // Silly test showing how to index documents w/o using Lucene's core
  // Document nor Field class
  public void testArbitraryFields() throws Exception {

    final Directory dir = newDirectory();
    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);

    final int NUM_DOCS = atLeast(27);
    if (VERBOSE) {
      System.out.println("TEST: " + NUM_DOCS + " docs");
    }
    final int[] fieldsPerDoc = new int[NUM_DOCS];
    int baseCount = 0;

    for (int docCount = 0; docCount < NUM_DOCS; docCount++) {
      final int fieldCount = TestUtil.nextInt(random(), 1, 17);
      fieldsPerDoc[docCount] = fieldCount - 1;

      final int finalDocCount = docCount;
      if (VERBOSE) {
        System.out.println("TEST: " + fieldCount + " fields in doc " + docCount);
      }

      final int finalBaseCount = baseCount;
      baseCount += fieldCount - 1;

      Iterable<IndexableField> d =
          new Iterable<IndexableField>() {
            @Override
            public Iterator<IndexableField> iterator() {
              return new Iterator<IndexableField>() {
                int fieldUpto;

                @Override
                public boolean hasNext() {
                  return fieldUpto < fieldCount;
                }

                @Override
                public IndexableField next() {
                  assert fieldUpto < fieldCount;
                  if (fieldUpto == 0) {
                    fieldUpto = 1;
                    return newStringField("id", "" + finalDocCount, Field.Store.YES);
                  } else {
                    return new MyField(finalBaseCount + (fieldUpto++ - 1));
                  }
                }

                @Override
                public void remove() {
                  throw new UnsupportedOperationException();
                }
              };
            }
          };
      w.addDocument(d);
    }

    final IndexReader r = w.getReader();
    w.close();

    final IndexSearcher s = newSearcher(r);
    int counter = 0;
    for (int id = 0; id < NUM_DOCS; id++) {
      if (VERBOSE) {
        System.out.println(
            "TEST: verify doc id=" + id + " (" + fieldsPerDoc[id] + " fields) counter=" + counter);
      }

      final TopDocs hits = s.search(new TermQuery(new Term("id", "" + id)), 1);
      assertEquals(1, hits.totalHits.value);
      final int docID = hits.scoreDocs[0].doc;
      final Document doc = s.doc(docID);
      final int endCounter = counter + fieldsPerDoc[id];
      while (counter < endCounter) {
        final String name = "f" + counter;
        final int fieldID = counter % 10;

        final boolean stored = (counter & 1) == 0 || fieldID == 3;
        final boolean binary = fieldID == 3;
        final boolean indexed = fieldID != 3;

        final String stringValue;
        if (fieldID != 3 && fieldID != 9) {
          stringValue = "text " + counter;
        } else {
          stringValue = null;
        }

        // stored:
        if (stored) {
          IndexableField f = doc.getField(name);
          assertNotNull("doc " + id + " doesn't have field f" + counter, f);
          if (binary) {
            assertNotNull("doc " + id + " doesn't have field f" + counter, f);
            final BytesRef b = f.binaryValue();
            assertNotNull(b);
            assertEquals(10, b.length);
            for (int idx = 0; idx < 10; idx++) {
              assertEquals((byte) (idx + counter), b.bytes[b.offset + idx]);
            }
          } else {
            assert stringValue != null;
            assertEquals(stringValue, f.stringValue());
          }
        }

        if (indexed) {
          final boolean tv = counter % 2 == 1 && fieldID != 9;
          if (tv) {
            final Terms tfv = r.getTermVectors(docID).terms(name);
            assertNotNull(tfv);
            TermsEnum termsEnum = tfv.iterator();
            assertEquals(new BytesRef("" + counter), termsEnum.next());
            assertEquals(1, termsEnum.totalTermFreq());
            PostingsEnum dpEnum = termsEnum.postings(null, PostingsEnum.ALL);
            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
            assertEquals(1, dpEnum.freq());
            assertEquals(1, dpEnum.nextPosition());

            assertEquals(new BytesRef("text"), termsEnum.next());
            assertEquals(1, termsEnum.totalTermFreq());
            dpEnum = termsEnum.postings(dpEnum, PostingsEnum.ALL);
            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
            assertEquals(1, dpEnum.freq());
            assertEquals(0, dpEnum.nextPosition());

            assertNull(termsEnum.next());

            // TODO: offsets

          } else {
            Fields vectors = r.getTermVectors(docID);
            assertTrue(vectors == null || vectors.terms(name) == null);
          }

          BooleanQuery.Builder bq = new BooleanQuery.Builder();
          bq.add(new TermQuery(new Term("id", "" + id)), BooleanClause.Occur.MUST);
          bq.add(new TermQuery(new Term(name, "text")), BooleanClause.Occur.MUST);
          final TopDocs hits2 = s.search(bq.build(), 1);
          assertEquals(1, hits2.totalHits.value);
          assertEquals(docID, hits2.scoreDocs[0].doc);

          bq = new BooleanQuery.Builder();
          bq.add(new TermQuery(new Term("id", "" + id)), BooleanClause.Occur.MUST);
          bq.add(new TermQuery(new Term(name, "" + counter)), BooleanClause.Occur.MUST);
          final TopDocs hits3 = s.search(bq.build(), 1);
          assertEquals(1, hits3.totalHits.value);
          assertEquals(docID, hits3.scoreDocs[0].doc);
        }

        counter++;
      }
    }

    r.close();
    dir.close();
  }

