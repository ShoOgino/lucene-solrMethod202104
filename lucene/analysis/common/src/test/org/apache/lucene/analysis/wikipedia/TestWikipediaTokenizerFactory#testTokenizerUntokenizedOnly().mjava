  public void testTokenizerUntokenizedOnly() throws Exception {
    String test =
        "[[Category:a b c d]] [[Category:e f g]] [[link here]] [[link there]] ''italics here'' something ''more italics'' [[Category:h   i   j]]";
    Set<String> untoks = new HashSet<>();
    untoks.add(WikipediaTokenizer.CATEGORY);
    untoks.add(WikipediaTokenizer.ITALICS);
    Tokenizer tf =
        tokenizerFactory(
                WIKIPEDIA,
                TOKEN_OUTPUT,
                Integer.toString(WikipediaTokenizer.UNTOKENIZED_ONLY),
                UNTOKENIZED_TYPES,
                WikipediaTokenizer.CATEGORY + ", " + WikipediaTokenizer.ITALICS)
            .create(newAttributeFactory());
    tf.setReader(new StringReader(test));
    assertTokenStreamContents(
        tf,
        new String[] {
          "a b c d", "e f g", "link", "here", "link",
          "there", "italics here", "something", "more italics", "h   i   j"
        },
        new int[] {11, 32, 42, 47, 56, 61, 71, 86, 98, 124},
        new int[] {18, 37, 46, 51, 60, 66, 83, 95, 110, 133},
        new int[] {1, 1, 1, 1, 1, 1, 1, 1, 1, 1});
  }

