  // LUCENE-1072
  public void testExceptionFromTokenStream() throws IOException {
    Directory dir = newDirectory();
    IndexWriterConfig conf =
        newIndexWriterConfig(
            new Analyzer() {

              @Override
              public TokenStreamComponents createComponents(String fieldName) {
                MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);
                tokenizer.setEnableChecks(
                    false); // disable workflow checking as we forcefully close() in exceptional
                // cases.
                return new TokenStreamComponents(
                    tokenizer,
                    new TokenFilter(tokenizer) {
                      private int count = 0;

                      @Override
                      public boolean incrementToken() throws IOException {
                        if (count++ == 5) {
                          throw new IOException();
                        }
                        return input.incrementToken();
                      }

                      @Override
                      public void reset() throws IOException {
                        super.reset();
                        this.count = 0;
                      }
                    });
              }
            });
    conf.setMaxBufferedDocs(Math.max(3, conf.getMaxBufferedDocs()));
    conf.setMergePolicy(NoMergePolicy.INSTANCE);

    IndexWriter writer = new IndexWriter(dir, conf);

    Document brokenDoc = new Document();
    String contents = "aa bb cc dd ee ff gg hh ii jj kk";
    brokenDoc.add(newTextField("content", contents, Field.Store.NO));
    expectThrows(
        Exception.class,
        () -> {
          writer.addDocument(brokenDoc);
        });

    // Make sure we can add another normal document
    Document doc = new Document();
    doc.add(newTextField("content", "aa bb cc dd", Field.Store.NO));
    writer.addDocument(doc);

    // Make sure we can add another normal document
    doc = new Document();
    doc.add(newTextField("content", "aa bb cc dd", Field.Store.NO));
    writer.addDocument(doc);

    writer.close();
    IndexReader reader = DirectoryReader.open(dir);
    final Term t = new Term("content", "aa");
    assertEquals(3, reader.docFreq(t));

    // Make sure the doc that hit the exception was marked
    // as deleted:
    PostingsEnum tdocs =
        TestUtil.docs(random(), reader, t.field(), new BytesRef(t.text()), null, 0);

    final Bits liveDocs = MultiBits.getLiveDocs(reader);
    int count = 0;
    while (tdocs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
      if (liveDocs == null || liveDocs.get(tdocs.docID())) {
        count++;
      }
    }
    assertEquals(2, count);

    assertEquals(reader.docFreq(new Term("content", "gg")), 0);
    reader.close();
    dir.close();
  }

