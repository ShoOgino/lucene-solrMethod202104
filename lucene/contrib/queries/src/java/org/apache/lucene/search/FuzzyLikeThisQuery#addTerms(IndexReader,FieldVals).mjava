    private void addTerms(IndexReader reader,FieldVals f) throws IOException
    {
        if(f.queryString==null) return;
        TokenStream ts=analyzer.tokenStream(f.fieldName,new StringReader(f.queryString));
        CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
        
        int corpusNumDocs=reader.numDocs();
        Term internSavingTemplateTerm =new Term(f.fieldName); //optimization to avoid constructing new Term() objects
        HashSet<String> processedTerms=new HashSet<String>();
        while (ts.incrementToken()) 
        {
                String term = termAtt.toString();
        	if(!processedTerms.contains(term))
        	{
                  processedTerms.add(term);
                  ScoreTermQueue variantsQ=new ScoreTermQueue(MAX_VARIANTS_PER_TERM); //maxNum variants considered for any one term
                  float minScore=0;
                  Term startTerm=internSavingTemplateTerm.createTerm(term);
                  AttributeSource atts = new AttributeSource();
                  MultiTermQuery.MaxNonCompetitiveBoostAttribute maxBoostAtt =
                    atts.addAttribute(MultiTermQuery.MaxNonCompetitiveBoostAttribute.class);
                  FuzzyTermsEnum fe = new FuzzyTermsEnum(reader, atts, startTerm, f.minSimilarity, f.prefixLength);
                  //store the df so all variants use same idf
                  int df = reader.docFreq(startTerm);
                  int numVariants=0;
                  int totalVariantDocFreqs=0;
                  BytesRef possibleMatch;
                  MultiTermQuery.BoostAttribute boostAtt =
                    fe.attributes().addAttribute(MultiTermQuery.BoostAttribute.class);
                  while ((possibleMatch = fe.next()) != null) {
                      if (possibleMatch!=null) {
                        numVariants++;
                        totalVariantDocFreqs+=fe.docFreq();
                        float score=boostAtt.getBoost();
                        if (variantsQ.size() < MAX_VARIANTS_PER_TERM || score > minScore){
                          ScoreTerm st=new ScoreTerm(new Term(startTerm.field(), new BytesRef(possibleMatch)),score,startTerm);                    
                          variantsQ.insertWithOverflow(st);
                          minScore = variantsQ.top().score; // maintain minScore
                        }
                        maxBoostAtt.setMaxNonCompetitiveBoost(variantsQ.size() >= MAX_VARIANTS_PER_TERM ? minScore : Float.NEGATIVE_INFINITY);
                      }
                    }

                  if(numVariants>0)
                    {
                      int avgDf=totalVariantDocFreqs/numVariants;
                      if(df==0)//no direct match we can use as df for all variants 
	                {
	                    df=avgDf; //use avg df of all variants
	                }
	                
                    // take the top variants (scored by edit distance) and reset the score
                    // to include an IDF factor then add to the global queue for ranking 
                    // overall top query terms
                    int size = variantsQ.size();
                    for(int i = 0; i < size; i++)
	                {
	                  ScoreTerm st = variantsQ.pop();
	                  st.score=(st.score*st.score)*sim.idf(df,corpusNumDocs);
	                  q.insertWithOverflow(st);
	                }                            
                }
        	}
        }     
    }

