  private void oneShardTest() throws Exception {
    log.info("Running oneShardTest");

    // create a collection that has 1 shard and 3 replicas
    String testCollectionName = "c8n_1x3_commits";
    createCollection(testCollectionName, "conf1", 1, 3, 1);
    cloudClient.setDefaultCollection(testCollectionName);

    List<Replica> notLeaders =
        ensureAllReplicasAreActive(testCollectionName, "shard1", 1, 3, 30);
    assertTrue("Expected 2 replicas for collection " + testCollectionName
            + " but found " + notLeaders.size() + "; clusterState: "
            + printClusterStateInfo(),
        notLeaders.size() == 2);

    log.info("All replicas active for {}", testCollectionName);

    // let's put the leader in its own partition, no replicas can contact it now
    Replica leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, "shard1");
    if (log.isInfoEnabled()) {
      log.info("Creating partition to leader at {}", leader.getCoreUrl());
    }

    SocketProxy leaderProxy = getProxyForReplica(leader);
    leaderProxy.close();

    Replica replica = notLeaders.get(0);
    sendCommitWithRetry(replica);
    Thread.sleep(sleepMsBeforeHealPartition);

    cloudClient.getZkStateReader().forceUpdateCollection(testCollectionName); // get the latest state
    leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, "shard1");
    assertSame("Leader was not active", Replica.State.ACTIVE, leader.getState());

    if (log.isInfoEnabled()) {
      log.info("Healing partitioned replica at {}", leader.getCoreUrl());
    }
    leaderProxy.reopen();
    Thread.sleep(sleepMsBeforeHealPartition);

    // try to clean up
    attemptCollectionDelete(cloudClient, testCollectionName);

    log.info("oneShardTest completed OK");
  }

