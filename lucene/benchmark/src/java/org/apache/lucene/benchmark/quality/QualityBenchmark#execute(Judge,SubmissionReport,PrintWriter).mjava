  /**
   * Run the quality benchmark.
   *
   * @param judge the judge that can tell if a certain result doc is relevant for a certain quality
   *     query. If null, no judgements would be made. Usually null for a submission run.
   * @param submitRep submission report is created if non null.
   * @param qualityLog If not null, quality run data would be printed for each query.
   * @return QualityStats of each quality query that was executed.
   * @throws Exception if quality benchmark failed to run.
   */
  public QualityStats[] execute(Judge judge, SubmissionReport submitRep, PrintWriter qualityLog)
      throws Exception {
    int nQueries = Math.min(maxQueries, qualityQueries.length);
    QualityStats stats[] = new QualityStats[nQueries];
    for (int i = 0; i < nQueries; i++) {
      QualityQuery qq = qualityQueries[i];
      // generate query
      Query q = qqParser.parse(qq);
      // search with this query
      long t1 = System.currentTimeMillis();
      TopDocs td = searcher.search(q, maxResults);
      long searchTime = System.currentTimeMillis() - t1;
      // most likely we either submit or judge, but check both
      if (judge != null) {
        stats[i] = analyzeQueryResults(qq, q, td, judge, qualityLog, searchTime);
      }
      if (submitRep != null) {
        submitRep.report(qq, td, docNameField, searcher);
      }
    }
    if (submitRep != null) {
      submitRep.flush();
    }
    return stats;
  }

