  /** test that offsets are correct when mappingcharfilter is previously applied */
  public void testChangedOffsets() throws IOException {
    final NormalizeCharMap.Builder builder = new NormalizeCharMap.Builder();
    builder.add("a", "一二");
    builder.add("b", "二三");
    final NormalizeCharMap norm = builder.build();
    Analyzer analyzer =
        new Analyzer() {
          @Override
          protected TokenStreamComponents createComponents(String fieldName) {
            Tokenizer tokenizer = new StandardTokenizer();
            return new TokenStreamComponents(tokenizer, new CJKBigramFilter(tokenizer));
          }

          @Override
          protected Reader initReader(String fieldName, Reader reader) {
            return new MappingCharFilter(norm, reader);
          }
        };

    assertAnalyzesTo(
        analyzer, "ab", new String[] {"一二", "二二", "二三"}, new int[] {0, 0, 1}, new int[] {1, 1, 2});

    // note: offsets are strange since this is how the charfilter maps them...
    // before bigramming, the 4 tokens look like:
    //   { 0, 0, 1, 1 },
    //   { 0, 1, 1, 2 }

    analyzer.close();
  }

