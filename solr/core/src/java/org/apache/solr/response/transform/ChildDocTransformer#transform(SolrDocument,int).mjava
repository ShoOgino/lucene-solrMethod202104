  @Override
  public void transform(SolrDocument rootDoc, int rootDocId) {
    // note: this algorithm works if both if we have have _nest_path_  and also if we don't!

    try {

      // lookup what the *previous* rootDocId is, and figure which segment this is
      final SolrIndexSearcher searcher = context.getSearcher();
      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();
      final int seg = ReaderUtil.subIndex(rootDocId, leaves);
      final LeafReaderContext leafReaderContext = leaves.get(seg);
      final int segBaseId = leafReaderContext.docBase;
      final int segRootId = rootDocId - segBaseId;
      final BitSet segParentsBitSet = parentsFilter.getBitSet(leafReaderContext);
      final Bits liveDocs = leafReaderContext.reader().getLiveDocs();

      if (segParentsBitSet == null) {
        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,
            "Parent filter '" + parentsFilter + "' doesn't match any parent documents");
      }

      final int segPrevRootId = segRootId==0? -1: segParentsBitSet.prevSetBit(segRootId - 1); // can return -1 and that's okay

      if (segPrevRootId == (segRootId - 1)) {
        // doc has no children, return fast
        return;
      }

      // we'll need this soon...
      final SortedDocValues segPathDocValues = DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME);
      // passing a different SortedDocValues obj since the child documents which come after are of smaller docIDs,
      // and the iterator can not be reversed.
      // The root doc is the input document to be transformed, and is not necessarily the root doc of the block of docs.
      final String rootDocPath = getPathByDocId(segRootId, DocValues.getSorted(leafReaderContext.reader(), NEST_PATH_FIELD_NAME));

      // the key in the Map is the document's ancestors key (one above the parent), while the key in the intermediate
      // MultiMap is the direct child document's key(of the parent document)
      final Map<String, Multimap<String, SolrDocument>> pendingParentPathsToChildren = new HashMap<>();

      final int firstChildId = segBaseId + segPrevRootId + 1;
      int matches = 0;
      // Loop each child ID up to the parent (exclusive).
      for (int docId = firstChildId; docId < rootDocId; ++docId) {
        final int segDocId = docId - segBaseId;

        // check whether doc is "live"
        if (liveDocs != null && !liveDocs.get(segDocId)) {
          // doc is not "live"; return fast
          continue;
        }

        // get the path.  (note will default to ANON_CHILD_KEY if schema is not nested or empty string if blank)
        final String fullDocPath = getPathByDocId(segDocId, segPathDocValues);

        if (isNestedSchema && !fullDocPath.startsWith(rootDocPath)) {
          // is not a descendant of the transformed doc; return fast.
          continue;
        }

        // Is this doc a direct ancestor of another doc we've seen?
        boolean isAncestor = pendingParentPathsToChildren.containsKey(fullDocPath);

        // Do we need to do anything with this doc (either ancestor or matched the child query)
        if (isAncestor || childDocSet == null || childDocSet.exists(docId)) {

          // If we reached the limit, only add if it's an ancestor
          if (limit != -1 && matches >= limit && !isAncestor) {
            continue;
          }
          ++matches; // note: includes ancestors that are not necessarily in childDocSet

          // load the doc
          SolrDocument doc = searcher.getDocFetcher().solrDoc(docId, childReturnFields);
          if(childReturnFields.getTransformer() != null) {
            if(childReturnFields.getTransformer().context == null) {
              childReturnFields.getTransformer().setContext(context);
            }
            childReturnFields.getTransformer().transform(doc, docId);
          }

          if (isAncestor) {
            // if this path has pending child docs, add them.
            addChildrenToParent(doc, pendingParentPathsToChildren.remove(fullDocPath)); // no longer pending
          }

          // get parent path
          String parentDocPath = getParentPath(fullDocPath);
          String lastPath = getLastPath(fullDocPath);
          // put into pending:
          // trim path if the doc was inside array, see trimPathIfArrayDoc()
          // e.g. toppings#1/ingredients#1 -> outer map key toppings#1
          // -> inner MultiMap key ingredients
          // or lonely#/lonelyGrandChild# -> outer map key lonely#
          // -> inner MultiMap key lonelyGrandChild#
          pendingParentPathsToChildren.computeIfAbsent(parentDocPath, x -> ArrayListMultimap.create())
              .put(trimLastPoundIfArray(lastPath), doc); // multimap add (won't replace)
        }
      }

      if (pendingParentPathsToChildren.isEmpty()) {
        // no child docs matched the child filter; return fast.
        return;
      }

      // only children of parent remain
      assert pendingParentPathsToChildren.keySet().size() == 1;

      // size == 1, so get the last remaining entry
      addChildrenToParent(rootDoc, pendingParentPathsToChildren.values().iterator().next());

    } catch (IOException e) {
      //TODO DWS: reconsider this unusual error handling approach; shouldn't we rethrow?
      log.warn("Could not fetch child documents", e);
      rootDoc.put(getName(), "Could not fetch child documents");
    }
  }

