  /** Sole constructor. */
  public OrdsBlockTreeTermsReader(PostingsReaderBase postingsReader, SegmentReadState state)
      throws IOException {

    this.postingsReader = postingsReader;

    String termsFile =
        IndexFileNames.segmentFileName(
            state.segmentInfo.name, state.segmentSuffix, OrdsBlockTreeTermsWriter.TERMS_EXTENSION);
    in = state.directory.openInput(termsFile, state.context);

    boolean success = false;
    IndexInput indexIn = null;

    try {
      int version =
          CodecUtil.checkIndexHeader(
              in,
              OrdsBlockTreeTermsWriter.TERMS_CODEC_NAME,
              OrdsBlockTreeTermsWriter.VERSION_START,
              OrdsBlockTreeTermsWriter.VERSION_CURRENT,
              state.segmentInfo.getId(),
              state.segmentSuffix);

      String indexFile =
          IndexFileNames.segmentFileName(
              state.segmentInfo.name,
              state.segmentSuffix,
              OrdsBlockTreeTermsWriter.TERMS_INDEX_EXTENSION);
      indexIn = state.directory.openInput(indexFile, state.context);
      int indexVersion =
          CodecUtil.checkIndexHeader(
              indexIn,
              OrdsBlockTreeTermsWriter.TERMS_INDEX_CODEC_NAME,
              OrdsBlockTreeTermsWriter.VERSION_START,
              OrdsBlockTreeTermsWriter.VERSION_CURRENT,
              state.segmentInfo.getId(),
              state.segmentSuffix);
      if (indexVersion != version) {
        throw new CorruptIndexException(
            "mixmatched version files: " + in + "=" + version + "," + indexIn + "=" + indexVersion,
            indexIn);
      }

      // verify
      CodecUtil.checksumEntireFile(indexIn);

      // Have PostingsReader init itself
      postingsReader.init(in, state);

      // NOTE: data file is too costly to verify checksum against all the bytes on open,
      // but for now we at least verify proper structure of the checksum footer: which looks
      // for FOOTER_MAGIC + algorithmID. This is cheap and can detect some forms of corruption
      // such as file truncation.
      CodecUtil.retrieveChecksum(in);

      // Read per-field details
      seekDir(in);
      seekDir(indexIn);

      final int numFields = in.readVInt();
      if (numFields < 0) {
        throw new CorruptIndexException("invalid numFields: " + numFields, in);
      }

      for (int i = 0; i < numFields; i++) {
        final int field = in.readVInt();
        final long numTerms = in.readVLong();
        assert numTerms >= 0;
        // System.out.println("read field=" + field + " numTerms=" + numTerms + " i=" + i);
        final int numBytes = in.readVInt();
        final BytesRef code = new BytesRef(new byte[numBytes]);
        in.readBytes(code.bytes, 0, numBytes);
        code.length = numBytes;
        final Output rootCode = OrdsBlockTreeTermsWriter.FST_OUTPUTS.newOutput(code, 0, numTerms);
        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);
        assert fieldInfo != null : "field=" + field;
        assert numTerms <= Integer.MAX_VALUE;
        final long sumTotalTermFreq = in.readVLong();
        // when frequencies are omitted, sumDocFreq=totalTermFreq and we only write one value
        final long sumDocFreq =
            fieldInfo.getIndexOptions() == IndexOptions.DOCS ? sumTotalTermFreq : in.readVLong();
        final int docCount = in.readVInt();
        // System.out.println("  longsSize=" + longsSize);

        BytesRef minTerm = readBytesRef(in);
        BytesRef maxTerm = readBytesRef(in);
        if (docCount < 0
            || docCount > state.segmentInfo.maxDoc()) { // #docs with field must be <= #docs
          throw new CorruptIndexException(
              "invalid docCount: " + docCount + " maxDoc: " + state.segmentInfo.maxDoc(), in);
        }
        if (sumDocFreq < docCount) { // #postings must be >= #docs with field
          throw new CorruptIndexException(
              "invalid sumDocFreq: " + sumDocFreq + " docCount: " + docCount, in);
        }
        if (sumTotalTermFreq < sumDocFreq) { // #positions must be >= #postings
          throw new CorruptIndexException(
              "invalid sumTotalTermFreq: " + sumTotalTermFreq + " sumDocFreq: " + sumDocFreq, in);
        }
        final long indexStartFP = indexIn.readVLong();
        OrdsFieldReader previous =
            fields.put(
                fieldInfo.name,
                new OrdsFieldReader(
                    this,
                    fieldInfo,
                    numTerms,
                    rootCode,
                    sumTotalTermFreq,
                    sumDocFreq,
                    docCount,
                    indexStartFP,
                    indexIn,
                    minTerm,
                    maxTerm));
        if (previous != null) {
          throw new CorruptIndexException("duplicate field: " + fieldInfo.name, in);
        }
      }
      indexIn.close();

      success = true;
    } finally {
      if (!success) {
        // this.close() will close in:
        IOUtils.closeWhileHandlingException(indexIn, this);
      }
    }
  }

