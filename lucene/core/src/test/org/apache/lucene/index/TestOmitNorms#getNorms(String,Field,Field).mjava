  /**
   * Indexes at least 1 document with f1, and at least 1 document with f2. returns the norms for
   * "field".
   */
  NumericDocValues getNorms(String field, Field f1, Field f2) throws IOException {
    Directory dir = newDirectory();
    IndexWriterConfig iwc =
        newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy());
    RandomIndexWriter riw = new RandomIndexWriter(random(), dir, iwc);

    // add f1
    Document d = new Document();
    d.add(f1);
    riw.addDocument(d);

    // add f2
    d = new Document();
    d.add(f2);
    riw.addDocument(d);

    // add a mix of f1's and f2's
    int numExtraDocs = TestUtil.nextInt(random(), 1, 1000);
    for (int i = 0; i < numExtraDocs; i++) {
      d = new Document();
      d.add(random().nextBoolean() ? f1 : f2);
      riw.addDocument(d);
    }

    IndexReader ir1 = riw.getReader();
    // todo: generalize
    NumericDocValues norms1 = MultiDocValues.getNormValues(ir1, field);

    // fully merge and validate MultiNorms against single segment.
    riw.forceMerge(1);
    DirectoryReader ir2 = riw.getReader();
    NumericDocValues norms2 = getOnlyLeafReader(ir2).getNormValues(field);

    if (norms1 == null) {
      assertNull(norms2);
    } else {
      while (true) {
        int norms1DocID = norms1.nextDoc();
        int norms2DocID = norms2.nextDoc();
        while (norms1DocID < norms2DocID) {
          assertEquals(0, norms1.longValue());
          norms1DocID = norms1.nextDoc();
        }
        while (norms2DocID < norms1DocID) {
          assertEquals(0, norms2.longValue());
          norms2DocID = norms2.nextDoc();
        }
        if (norms1.docID() == NO_MORE_DOCS) {
          break;
        }
        assertEquals(norms1.longValue(), norms2.longValue());
      }
    }
    ir1.close();
    ir2.close();
    riw.close();
    dir.close();
    return norms1;
  }

