  @SuppressWarnings("deprecation")
  private static void initBrokenConstructors() {
    try {
      brokenConstructors.put(
          LimitTokenCountFilter.class.getConstructor(TokenStream.class, int.class), ALWAYS);
      brokenConstructors.put(
          LimitTokenCountFilter.class.getConstructor(TokenStream.class, int.class, boolean.class),
          args -> {
            assert args.length == 3;
            return !((Boolean) args[2]); // args are broken if consumeAllTokens is false
          });
      brokenConstructors.put(
          LimitTokenOffsetFilter.class.getConstructor(TokenStream.class, int.class), ALWAYS);
      brokenConstructors.put(
          LimitTokenOffsetFilter.class.getConstructor(TokenStream.class, int.class, boolean.class),
          args -> {
            assert args.length == 3;
            return !((Boolean) args[2]); // args are broken if consumeAllTokens is false
          });
      brokenConstructors.put(
          LimitTokenPositionFilter.class.getConstructor(TokenStream.class, int.class), ALWAYS);
      brokenConstructors.put(
          LimitTokenPositionFilter.class.getConstructor(
              TokenStream.class, int.class, boolean.class),
          args -> {
            assert args.length == 3;
            return !((Boolean) args[2]); // args are broken if consumeAllTokens is false
          });
      for (Class<?> c :
          Arrays.<Class<?>>asList(
              // doesn't actual reset itself!  TODO this statement is probably obsolete as of
              // LUCENE-6121 ?
              CachingTokenFilter.class,
              // LUCENE-8092: doesn't handle graph inputs
              CJKBigramFilter.class,
              // TODO: LUCENE-4983
              CommonGramsFilter.class,
              // TODO: doesn't handle graph inputs
              CommonGramsQueryFilter.class,
              // Not broken, simulates brokenness:
              CrankyTokenFilter.class,
              // TODO: doesn't handle graph inputs (or even look at positionIncrement)
              HyphenatedWordsFilter.class,
              // broken offsets
              PathHierarchyTokenizer.class,
              // broken offsets
              ReversePathHierarchyTokenizer.class,
              // Not broken: we forcefully add this, so we shouldn't
              // also randomly pick it:
              ValidatingTokenFilter.class,
              // TODO: it seems to mess up offsets!?
              WikipediaTokenizer.class,
              // TODO: needs to be a tokenizer, doesnt handle graph inputs properly (a shingle or
              // similar following will then cause pain)
              WordDelimiterFilter.class,
              // Cannot correct offsets when a char filter had changed them:
              WordDelimiterGraphFilter.class,
              // requires a special encoded token value, so it may fail with random data:
              DelimitedTermFrequencyTokenFilter.class,
              // requires a special encoded token value, so it may fail with random data:
              DelimitedBoostTokenFilter.class,
              // clones of core's filters:
              org.apache.lucene.analysis.core.StopFilter.class,
              org.apache.lucene.analysis.core.LowerCaseFilter.class)) {
        for (Constructor<?> ctor : c.getConstructors()) {
          brokenConstructors.put(ctor, ALWAYS);
        }
      }
    } catch (Exception e) {
      throw new Error(e);
    }
  }

