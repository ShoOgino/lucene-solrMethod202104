    /**
     * By delegating work to {@link PerReplicaStatesOps} for per replica state updates, and using optimistic locking
     * (with retries) to directly update the content of {@code state.json}, updates Zookeeper with the changes computed
     * by the {@link StateChangeCalculator}.
     */
    private void applyUpdate() throws KeeperException, InterruptedException {
      /* Initial slightly naive implementation (later on we should consider some caching between updates...).
       * For updates:
       * - Read the state.json file from Zookeeper
       * - Run the updater to execute the changes on top of that file
       * - Compare and Swap the file with the new version (fail if something else changed ZK in the meantime)
       * - Retry a few times all above steps if update is failing.
       *
       * For creations:
       * - Build the state.json file using the updater
       * - Try to write it to Zookeeper (do not overwrite if it exists)
       * - Fail (without retries) if write failed.
       */

      // Note we DO NOT track nor use the live nodes in the cluster state.
      // That may means the two abstractions (collection metadata vs. nodes) should be separated.
      // For now trying to diverge as little as possible from existing data structures and code given the need to
      // support both the old way (Overseer) and new way (distributed) of handling cluster state update.
      final Set<String> liveNodes = Collections.emptySet();

      // Per Replica States updates are done before all other updates and not subject to the number of attempts of CAS
      // made here, given they have their own CAS strategy and implementation (see PerReplicaStatesOps.persist()).
      boolean firstAttempt = true;

      // When there are multiple retries of state.json write and the cluster state gets updated over and over again with
      // the changes done in the per replica states, we avoid refetching those multiple times.
      PerReplicaStates fetchedPerReplicaStates = null;

      // Later on (when Collection API commands are distributed) we will have to rely on the version of state.json
      // to implement the replacement of Collection API locking. Then we should not blindly retry cluster state updates
      // as we do here but instead intelligently fail (or retry completely) the Collection API call when seeing that
      // state.json was changed by a concurrent command execution.
      // The loop below is ok for distributing cluster state updates from Overseer to all nodes while Collection API
      // commands are still executed on the Overseer and manage their locking the old fashioned way.
      for (int attempt = 0; attempt < CAS_MAX_ATTEMPTS; attempt++) {
        // Start by reading the current state.json (if this is an update).
        // TODO Eventually rethink the way each node manages and caches its copy of the cluster state. Knowing about all collections in the cluster might not be needed.
        ClusterState initialClusterState;
        if (updater.isCollectionCreation()) {
          initialClusterState = new ClusterState(liveNodes, Collections.emptyMap());
        } else {
          // Get the state for existing data in ZK (and if no data exists we should fail)
          initialClusterState = fetchStateForCollection();
        }

        // Apply the desired changes. Note that the cluster state passed to the chain of mutators is totally up to date
        // (it's read from ZK just above). So assumptions made in the mutators (like SliceMutator.removeReplica() deleting
        // the whole collection if it's not found) are ok. Actually in the removeReplica case, the collection will always
        // exist otherwise the call to fetchStateForCollection() above would have failed.
        updater.computeUpdates(initialClusterState);

        ClusterState updatedState = updater.getUpdatedClusterState();
        List<PerReplicaStatesOps> allStatesOps = updater.getPerReplicaStatesOps();

        if (firstAttempt && allStatesOps != null) {
          // Do the per replica states updates (if any) before the state.json update (if any)
          firstAttempt = false;

          // The parent node of the per replica state nodes happens to be the node of state.json.
          String prsParentNode = ZkStateReader.getCollectionPath(updater.getCollectionName());

          for (PerReplicaStatesOps prso : allStatesOps) {
            prso.persist(prsParentNode, zkStateReader.getZkClient());
          }
        }

        if (updatedState == null) {
          // No update to state.json needed
          return;
        }

        // Get the latest version of the collection from the cluster state first.
        // There is no notion of "cached" here (the boolean passed below) as we the updatedState is based on CollectionRef
        DocCollection docCollection = updatedState.getCollectionOrNull(updater.getCollectionName(), true);

        // If we did update per replica states and we're also updating state.json, update the content of state.json to reflect
        // the changes made to replica states. Not strictly necessary (the state source of truth is in per replica states), but nice to have...
        if (allStatesOps != null) {
          if (docCollection != null) {
            // Fetch the per replica states updates done previously or skip fetching if we already have them
            fetchedPerReplicaStates = PerReplicaStates.fetch(docCollection.getZNode(), zkStateReader.getZkClient(), fetchedPerReplicaStates);
            // Transpose the per replica states into the cluster state
            updatedState = updatedState.copyWith(updater.getCollectionName(), docCollection.copyWith(fetchedPerReplicaStates));
          }
        }

        try {
          // Try to do a conditional update (a.k.a. CAS: compare and swap).
          doStateDotJsonCasUpdate(updatedState);
          return; // state.json updated successfully.
        } catch (KeeperException.BadVersionException bve) {
          if (updater.isCollectionCreation()) {
            // Not expecting to see this exception when creating new state.json fails, so throwing it up the food chain.
            throw bve;
          }
        }
        // We've tried to update an existing state.json and got a BadVersionException. We'll try again a few times.
        // When only two threads compete, no point in waiting: if we lost this time we'll get it next time right away.
        // But if more threads compete, then waiting a bit (random delay) can improve our chances. The delay should likely
        // be proportional to the time between reading the cluster state and updating it. We can measure it in the loop above.
        // With "per replica states" collections, concurrent attempts of even just two threads are expected to be extremely rare.
      }

      // We made quite a few attempts but failed repeatedly. This is pretty bad but we can't loop trying forever.
      // Offering a job to the Overseer wouldn't usually fail if the ZK queue can be written to (but the Overseer can then
      // loop forever attempting the update).
      // We do want whoever called us to fail right away rather than to wait for a cluster change and timeout because it
      // didn't happen. Likely need to review call by call what is the appropriate behaviour, especially once Collection
      // API is distributed (because then the Collection API call will fail if the underlying cluster state update cannot
      // be done, and that's a desirable thing).
      throw new KeeperException.BadVersionException(ZkStateReader.getCollectionPath(updater.getCollectionName()));
    }

