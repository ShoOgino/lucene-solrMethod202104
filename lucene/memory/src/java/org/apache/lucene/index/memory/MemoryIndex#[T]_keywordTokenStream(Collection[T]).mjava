  /**
   * Convenience method; Creates and returns a token stream that generates a token for each keyword
   * in the given collection, "as is", without any transforming text analysis. The resulting token
   * stream can be fed into {@link #addField(String, TokenStream)}, perhaps wrapped into another
   * {@link org.apache.lucene.analysis.TokenFilter}, as desired.
   *
   * @param keywords the keywords to generate tokens for
   * @return the corresponding token stream
   */
  public <T> TokenStream keywordTokenStream(final Collection<T> keywords) {
    // TODO: deprecate & move this method into AnalyzerUtil?
    if (keywords == null) throw new IllegalArgumentException("keywords must not be null");

    return new TokenStream() {
      private Iterator<T> iter = keywords.iterator();
      private int start = 0;
      private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
      private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);

      @Override
      public boolean incrementToken() {
        if (!iter.hasNext()) return false;

        T obj = iter.next();
        if (obj == null) throw new IllegalArgumentException("keyword must not be null");

        String term = obj.toString();
        clearAttributes();
        termAtt.setEmpty().append(term);
        offsetAtt.setOffset(start, start + termAtt.length());
        start += term.length() + 1; // separate words by 1 (blank) character
        return true;
      }
    };
  }

