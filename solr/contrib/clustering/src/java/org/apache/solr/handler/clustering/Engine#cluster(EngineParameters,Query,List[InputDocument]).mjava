  List<Cluster<InputDocument>> cluster(EngineParameters parameters, Query query, List<InputDocument> documents) {
    try {
      checkParameters(parameters);

      ClusteringAlgorithm algorithm = engineContext.getAlgorithm(parameters.algorithmName());
      populateAlgorithmParameters(query, parameters, algorithm);

      // Sort documents by ID so that results are not order-sensitive.
      documents.sort(Comparator.comparing(a -> a.getId().toString()));

      // Split documents into language groups.
      String defaultLanguage = parameters.language();
      Map<String, List<InputDocument>> documentsByLanguage =
          documents.stream()
              .collect(
                  Collectors.groupingBy(
                      doc -> {
                        String lang = doc.language();
                        return lang == null ? defaultLanguage : lang;
                      }));

      // Cluster documents within each language group.
      HashSet<String> warnOnce = new HashSet<>();
      LinkedHashMap<String, List<Cluster<InputDocument>>> clustersByLanguage =
          new LinkedHashMap<>();
      for (Map.Entry<String, List<InputDocument>> e : documentsByLanguage.entrySet()) {
        String lang = e.getKey();
        if (!engineContext.isLanguageSupported(lang)) {
          if (warnOnce.add(lang)) {
            log.warn(
                "Language '{}' is not supported, documents in this "
                    + "language will not be clustered.", lang);
          }
        } else {
          LanguageComponents langComponents = engineContext.getLanguage(lang);
          if (!algorithm.supports(langComponents)) {
            if (warnOnce.add(lang)) {
              log.warn(
                  "Language '{}' is not supported by algorithm '{}', documents in this "
                      + "language will not be clustered.", lang, parameters.algorithmName());
            }
          } else {
            clustersByLanguage.put(
                lang, algorithm.cluster(e.getValue().stream(), langComponents));
          }
        }
      }

      List<Cluster<InputDocument>> clusters;
      if (clustersByLanguage.size() == 1) {
        clusters = clustersByLanguage.values().iterator().next();
      } else {
        clusters = clustersByLanguage.entrySet().stream()
            .map(e -> {
              Cluster<InputDocument> cluster = new Cluster<>();
              cluster.addLabel(e.getKey());
              e.getValue().forEach(cluster::addCluster);
              return cluster;
            })
            .collect(Collectors.toList());
      }

      return clusters;
    } catch (Exception e) {
      log.error("Clustering request failed.", e);
      throw new SolrException(ErrorCode.SERVER_ERROR, "Carrot2 clustering failed", e);
    }
  }

